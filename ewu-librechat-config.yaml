version: 1.2.4

fileConfig:
  endpoints:
    all:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
    openAI:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
    google:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
    anthropic:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
    Mistral:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
    assistants:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
    custom:
      fileLimit: 50
      fileSizeLimit: 100
      rateLimitCount: 100
      rateLimitDuration: 60
  fileLimit: 50
  fileSizeLimit: 100
  rateLimitCount: 100
  rateLimitDuration: 60
  supportedMimeTypes:
    - "image/jpeg"
    - "image/png"
    - "image/gif"
    - "image/webp"
    - "image/svg+xml"
    - "text/plain"
    - "text/css"
    - "text/javascript"
    - "text/html"
    - "application/json"
    - "application/pdf"
    - "application/msword"
    - "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    - "application/vnd.ms-excel"
    - "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"

cache: true

registration:
  socialLogins:
    - "discord"
    - "facebook"
    - "github"
    - "google"
    - "openid"

endpoints:
  agents:
    recursionLimit: 30
    maxIterations: 30
    timeout: 60000
    langgraph:
      recursionLimit: 30
      options:
        recursionLimit: 30
        maxIterations: 30

  custom:
    - name: "Flux"
      apiKey: "${FLUX_API_KEY}"
      baseURL: "https://api.bfl.ai/v1"
      models:
        default:
          - flux-kontext-pro
          - flux-kontext-max
          - flux-pro-1.1-ultra
          - flux-pro-1.1
          - flux-pro
          - flux-dev
      fetch: false
      titleConvo: true
      titleModel: "flux-model"
      modelDisplayLabel: "Flux"

    - name: "APIpie"
      apiKey: "${APIPIE_API_KEY}"
      baseURL: "https://apipie.ai/v1/"
      models:
        default:
          - DeepSeek-R1
          - DeepSeek-R1-Distill-Llama-70B
          - DeepSeek-R1-Distill-Qwen-1.5B
          - DeepSeek-R1-Distill-Qwen-14B
          - DeepSeek-R1-Distill-Qwen-32B
          - DeepSeek-R1-Turbo
          - DeepSeek-V3
          - DeepSeek-V3-0324
          - DeepSeek-V3-p-dp
          - Hermes-3-Llama-3.1-405B
          # ... (weitere Modelle nach Bedarf)
      fetch: false
      modelDisplayLabel: "APIpie"

    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default:
          - r1-1776
          - sonar
          - sonar-deep-research
          - sonar-pro
          - sonar-reasoning
          - sonar-reasoning-pro
      fetch: false
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      summarize: false
      summaryModel: "llama-3.1-sonar-small-128k-chat"
      forcePrompt: false
      dropParams:
        - "stop"
        - "frequency_penalty"
      modelDisplayLabel: "Perplexity"

    - name: "SambaNova"
      iconURL: "https://sambanova.ai/hubfs/logotype_sambanova_orange.png"
      apiKey: "${SAMBANOVA_API_KEY}"
      baseURL: "https://api.sambanova.ai/v1/"
      models:
        default:
          - DeepSeek-R1
          - DeepSeek-R1-Distill-Llama-70B
          - Llama-3.1-Tulu-3-405B
          # ... (weitere Modelle nach Bedarf)
      fetch: false
      titleConvo: true
      titleModel: "Meta-Llama-3.1-8B-Instruct"
      modelDisplayLabel: "SambaNova"

    - name: "together.ai"
      apiKey: "${TOGETHERAI_API_KEY}"
      baseURL: "https://api.together.xyz"
      models:
        default:
          - Gryphe/MythoMax-L2-13b
          - Gryphe/MythoMax-L2-13b-Lite
          # ... (weitere Modelle nach Bedarf)
      fetch: false
      titleConvo: true
      titleModel: "togethercomputer/llama-2-7b-chat"
      summarize: false
      summaryModel: "togethercomputer/llama-2-7b-chat"
      forcePrompt: false
      modelDisplayLabel: "together.ai"

    - name: "Unify"
      apiKey: "${UNIFY_API_KEY}"
      baseURL: "https://api.unify.ai/v0/"
      models:
        default:
          - chatgpt-4o-latest@openai
          # ... (weitere Modelle nach Bedarf)
      fetch: false
      titleConvo: true
      titleModel: "gpt-4o-mini@openai"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"

    - name: "xai"
      apiKey: "${XAI_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default:
          - grok-2-1212
          - grok-2-vision-1212
          # ... (weitere Modelle nach Bedarf)
      fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "grok-beta"
      summarize: false
      summaryModel: "grok-beta"
      forcePrompt: false
      modelDisplayLabel: "Grok"

    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default:
          - codestral-2501
          - codestral-latest
          - ministral-3b
          - ministral-8b
          - mistral-large-2411
          - mistral-large-latest
          - mistral-small-24b-instruct-2501
          - mistral-small-latest
          - pixtral-12b-2409
          - pixtral-large-2411
          - pixtral-large-latest
      fetch: false
      titleConvo: true
      titleModel: "mistral-small-latest"
      summarize: false
      summaryModel: "mistral-small-latest"
      forcePrompt: false
      modelDisplayLabel: "Mistral"
